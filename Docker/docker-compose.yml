version: '3.8' # This version tag is becoming obsolete but doesn't hurt for now

services:
  openvoice:
    build:
      context: .. # Relative to this docker-compose.yml, context is "Magenta AI"
      dockerfile: Docker/Dockerfile # Path to Dockerfile relative to context
    container_name: docker-openvoice
    ports:
      - "8000:8000"
    volumes:
      # Assumes checkpoints_v2 is in "Magenta AI/checkpoints_v2"
      - ../checkpoints_v2:/app/checkpoints_v2:ro
    environment:
      - PYTHONUNBUFFERED=1
    restart: unless-stopped
    networks:
      - app-network

  voice-similarity:
    build:
      context: .. # Relative to this docker-compose.yml, context is "Magenta AI"
      dockerfile: Docker/Dockerfile.similarity # Path to Dockerfile relative to context
    container_name: docker-voice-similarity
    ports:
      - "8001:8001"
    volumes:
      # This volume caches downloaded SpeechBrain models on your host
      # Creates/uses "Magenta AI/Docker/pretrained_models_similarity" on the host
      - ./pretrained_models_similarity:/app/pretrained_models
    environment:
      - PYTHONUNBUFFERED=1
    restart: unless-stopped
    networks:
      - app-network

  cosyvoice:
    build:
      context: .. # Relative to this docker-compose.yml, context is "Magenta AI"
      dockerfile: Docker/Dockerfile.cosyvoice # Path to Dockerfile relative to context
    container_name: docker-cosyvoice
    ports:
      - "8002:8000" # Expose CosyVoice API on host port 8002, container port 8000
    volumes:
      # --- THIS IS THE CRITICAL CORRECTION ---
      # Host path is relative to THIS docker-compose.yml file (which is in Magenta AI/Docker/)
      # So, ../ goes up to "Magenta AI", then we go into "Backend/CosyVoice/pretrained_models"
      # This mounts your existing downloaded models from the host into the container.
      - ../Backend/CosyVoice/pretrained_models:/app/CosyVoice/pretrained_models:ro
    # If using GPU (uncomment and configure if you have an NVIDIA GPU and drivers):
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1 # Or 'all'
    #           capabilities: [gpu]
    environment:
      - PYTHONUNBUFFERED=1
      - TOKENIZERS_PARALLELISM=false # Good practice for Hugging Face tokenizers
      # Add any other environment variables CosyVoice might need
    restart: unless-stopped
    networks:
      - app-network

networks:
  app-network:
    driver: bridge

# This 'volumes:' block defines Docker-managed named volumes.
# Since we are using specific host-path bind mounts for model persistence in the service definitions,
# these named volumes here are not strictly mapping to those.
# For example, 'pretrained_models_similarity' in the voice-similarity service uses a BIND MOUNT
# to './pretrained_models_similarity' on the host.
# If you intended to use a DOCKER NAMED VOLUME for that, the service definition would be:
#    volumes:
#      - pretrained_models_similarity:/app/pretrained_models
# And then this block below would correctly define that named volume.
# For clarity, I will leave this block as is, but understand the distinction.
# The cosyvoice service is definitely using a BIND MOUNT to your host's Backend/... folder.
volumes:
  pretrained_models_similarity:
  pretrained_cosyvoice_models: # This name is defined but the service above uses a specific host path bind mount.