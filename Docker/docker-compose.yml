version: '3.8'
services:
  openvoice: # This is your service name
    build:
      context: ..  # Build context is one level up (Magenta AI directory)
      dockerfile: Docker/Dockerfile # Path to your Dockerfile, relative to the context
    ports:
      - "8000:8000"
    volumes:
      # This volume is for any files the API might write out temporarily or persistently
      - openvoice_data:/app/processed 
      
      # THIS IS THE CORRECTED BIND MOUNT FOR YOUR CHECKPOINTS
      # It maps your local "Magenta AI/checkpoints_v2" to "/app/checkpoints_v2" inside the container
      - ../checkpoints_v2:/app/checkpoints_v2:ro 
      # ':ro' makes the mount read-only inside the container, which is good for model files
      
    environment:
      - PYTHONUNBUFFERED=1 # Ensures Python output (like prints) is not buffered
      - HF_HOME=/app/huggingface_cache # Optional: good for managing Hugging Face cache within container/volume
      # You might need to add HUGGINGFACE_TOKEN if OpenVoice or its deps need it for downloads
      # - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN} # Pass from your host .env if needed

    restart: unless-stopped

# This defines a named volume for persistent data generated by the app (if any)
# We don't need to define 'openvoice_checkpoints' as a named volume if using a bind mount for checkpoints.
volumes:
  openvoice_data:
  # huggingface_cache: # Optional: if you want to persist HF cache across container rebuilds